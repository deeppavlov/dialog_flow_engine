{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This tutorial will make you acquianted with all basic DialogFlow features.\n",
    "\n",
    "<a id='legend'></a>\n",
    "In this tutorial, we will illustrate the DialogFlow functionality using the following notation.\n",
    "<img src=\"notation.png\" width=\"600\" height=\"800\"> \n",
    "\n",
    "Here are the links on the examples:\n",
    "[Example 1](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_1_basics.py)\n",
    "[Example 2](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_2_conditions.py)\n",
    "[Example 3](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_3_responses.py)\n",
    "[Example 4](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_4_transitions.py)\n",
    "[Example 5](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_5_global_transitions.py)\n",
    "[Example 6](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_6_context_serialization.py)\n",
    "[Example 7](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_7_pre_response_processing.py)\n",
    "[Example 8](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_8_misc.py)\n",
    "[Example 9](https://github.com/deepmipt/dialog_flow_engine/blob/dev/example/example_9_pre_transitions_processing.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='actor'></a>\n",
    "\n",
    "The object that executes dialog is `Actor`. After we define `script`, we initialize `Actor` with script, start node, fallback node and default label priority.\n",
    "\n",
    "Start node is the node where the dialog starts. Fallback node is the node where the dialog goes when there are no available transitions. \n",
    "\n",
    "The dialog is defined in `script`. The `script` is a flow dictionary that contains `flows` and the optional `GLOBAL` field with parameters.\n",
    "\n",
    "Every `flow` is also a dictionary that has multiple `nodes` and the optional `LOCAL` field with parameters. It can be convenient to denote every topic by separate `flows`. \n",
    "\n",
    "<a id='node'></a>\n",
    "\n",
    "`Node` is the basic element of the framework. It has the same structure as `LOCAL` and `GLOBAL`.\n",
    "\n",
    "<img src=\"script_flow_local_global_node.png\" width=\"1200\" height=\"600\"> \n",
    "\n",
    "Here is the content of this structure. It is described in details below. \n",
    "\n",
    "<img src=\"4_keywords.png\" width=\"1200\" height=\"600\">\n",
    "\n",
    "<img src=\"misc.png\" width=\"300\" height=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='response'></a>\n",
    "\n",
    "`Node` is a dictionary, where the key is the name of node, and value is the dictionary with following keys:\n",
    "\n",
    "\n",
    "* `PRE_RESPONSE_PROCESSING` ( OPTIONAL) contains the dictionary of preprocessings that are applied to the response.\n",
    "\n",
    "* `RESPONSE` contains the response the node outputs. Response can be a string or a function. \n",
    "If `RESPONSE` is a function, it must take `Context` and `Actor` as first and second argument respectively, just like here.\n",
    "\n",
    "\n",
    "```\n",
    "def cannot_talk_about_topic_response(ctx: Context, actor: Actor, *args, **kwargs) -> Any:\n",
    "    request = ctx.last_request\n",
    "    topic_pattern = re.compile(r\"(.*talk about )(.*)\\.\")\n",
    "    topic = topic_pattern.findall(request)\n",
    "    topic = topic and topic[0] and topic[0][-1]\n",
    "    if topic:\n",
    "        return f\"Sorry, I can not talk about {topic} now.\"\n",
    "    else:\n",
    "        return \"Sorry, I can not talk about that now.\"\n",
    "```\n",
    "\n",
    "\n",
    "Response function can take different arguments, but in this case it must be called with these arguments in script, like here.\n",
    "\n",
    "```\n",
    "def upper_case_response(response: str):\n",
    "    # wrapper for internal response function\n",
    "    def cannot_talk_about_topic_response(ctx: Context, actor: Actor, *args, **kwargs) -> Any:\n",
    "        return response.upper()\n",
    "\n",
    "    return cannot_talk_about_topic_response\n",
    "```\n",
    "\n",
    "You can see examples of working with response functions in [Example 3](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_3_responses.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='response2'></a>\n",
    "\n",
    "\n",
    "If `RESPONSE` is a function, and in `PRE_RESPONSE_PROCESSING` you modify response string, you must call the function in `PRE_RESPONSE_PROCESSING`,  like here:\n",
    "```\n",
    "def add_prefix(prefix):\n",
    "    def add_prefix_processing(ctx: Context, actor: Actor, *args, **kwargs) -> Context:\n",
    "        processed_node = ctx.current_node\n",
    "        processed_node.response = f\"{prefix}: {processed_node.response}\"\n",
    "        ctx.overwrite_current_node_in_processing(processed_node)\n",
    "        return ctx\n",
    "\n",
    "    return add_prefix_processing\n",
    "```\n",
    "\n",
    "and then\n",
    "\n",
    "```\n",
    "    GLOBAL: {\n",
    "        PRE_RESPONSE_PROCESSING: {\n",
    "            \"proc_name_1\": add_prefix(\"l1_global\"),\n",
    "            \"proc_name_2\": add_prefix(\"l2_global\"),\n",
    "        }\n",
    "    },\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='transition'></a>\n",
    "\n",
    "* `PRE_TRANSITION_PROCESSING`  ( OPTIONAL) contains the dictionary of preprocessings that are applied to the transition.\n",
    "\n",
    "* `TRANSITIONS` contains the dictionary of transitions from this node to other nodes. In each dictionary, key is the tuple (next_flow, next_node), and value is the condition of transition to this flow and node.\n",
    "\n",
    "<a id='selecting'></a>\n",
    "\n",
    "Here is how the we choose the transition to execute.\n",
    "\n",
    "<img src=\"choose_transitions.png\" width=\"800\" height=\"600\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='misc'></a>\n",
    "\n",
    "* `MISC` is an optional dictionary of values that can be accessed by any other functions.\n",
    "\n",
    "<img src=\"misc.png\" width=\"600\" height=\"600\"> \n",
    "\n",
    "\n",
    "\n",
    "You can see examples of working with `MISC` in [Example 8](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_8_misc.py). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dfe_labels'></a>\n",
    "\n",
    "Note that in `TRANSITIONS`, function from `dff_engine.labels` can also be the keys. You can see what different functions do in this picture.\n",
    "\n",
    "<img src=\"dfe_labels.png\" width=\"800\" height=\"600\"> \n",
    "\n",
    "You can find examples of using these functions in [Example 4](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_4_transitions.py), [Example 7](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_7_pre_response_processing.py), [Example 8](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_8_misc.py) and [Example 9](https://github.com/deepmipt/dialog_flow_engine/blob/dev/example/example_9_pre_transitions_processing.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dfe_condition'></a>\n",
    "\n",
    "Also, for every transition, the possible conditions supported by the library is shown here.\n",
    "\n",
    "<img src=\"dfe_condition.png\" width=\"600\" height=\"400\"> \n",
    "\n",
    "You can also make your own condition function, but it must take `Context` and Actor as first and second argument respectively, just like the response function. Such function can be passed as a value without evaluating.\n",
    "Here is the example of such function.\n",
    "\n",
    "```\n",
    "def hi_lower_case_condition(ctx: Context, actor: Actor, *args, **kwargs) -> bool:\n",
    "    request = ctx.last_request\n",
    "    return \"hi\" in request.lower()\n",
    "```\n",
    "\n",
    "You can also pass as a condition function that takes different arguments, but it must return function that takes `Context` and `Actor`.\n",
    "Here is the example of such function.\n",
    "\n",
    "```\n",
    "def predetermined_condition(condition: bool):\n",
    "    # wrapper for internal condition function\n",
    "    def internal_condition_function(ctx: Context, actor: Actor, *args, **kwargs) -> bool:\n",
    "        # It always returns `condition`.\n",
    "        return condition\n",
    "\n",
    "    return internal_condition_function\n",
    "```\n",
    "\n",
    "\n",
    "You can find examples of working with conditions in [Example 2](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_2_conditions.py).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='local_global'></a>\n",
    "\n",
    "`LOCAL` and `GLOBAL` have the same structure as `Node`.You can see examples of using `GLOBAL` in [Example 5](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_5_global_transitions.py),[Example 7](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_7_pre_response_processing.py),[Example 8](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_8_misc.py) and [Example 9](https://github.com/deepmipt/dialog_flow_engine/blob/dev/example/example_9_pre_transitions_processing.py)\n",
    "Among these examples, `LOCAL` is used in [Example 7](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_7_pre_response_processing.py) and [Example 8](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_8_misc.py).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='overwrite'></a>\n",
    "\n",
    "\n",
    "Any variable from `PRE_TRANSITION_PROCESSING`,`PRE_RESPONSE_PROCESSING`,`TRANSITIONS` and  `MISC` from every level can be overwritten on the lower level.\n",
    "\n",
    "<img src=\"overwriting_all_variables.png\" width=\"800\" height=\"600\"> \n",
    "\n",
    "You can see the example of overwriting `TRANSITIONS` in [Example 5](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_5_global_transitions.py), examples of overwriting `PRE_TRANSITION_PROCESSING` values in [Example 7](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_7_pre_response_processing.py), examples of overwriting `MISC` values in [Example 8](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_8_misc.py) and examples of overwriting `PRE_TRANSITION_PROCESSING` in [Example 9](https://github.com/deepmipt/dialog_flow_engine/blob/dev/example/example_9_pre_transitions_processing.py).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='turn_handler'></a>\n",
    "\n",
    "\n",
    "Turn_handler is a function that obtains bot answer for every turn. It adds a next user request, `in_request`, into the `context`. Then `Actor` processes the `context`, in function the response is logged, and the response along with the `context` is returned.\n",
    "\n",
    "Note that  `context` can be serialized to dict or to the json string, as in [Example 6](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_6_context_serialization.py).\n",
    "\n",
    "You can see the simple example of `turn_handler` in [Example 1](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_1_basics.py).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from df_engine.core.keywords import GLOBAL, TRANSITIONS, RESPONSE, MISC, LOCAL\n",
    "from df_engine.core.keywords import PRE_RESPONSE_PROCESSING, PRE_TRANSITIONS_PROCESSING\n",
    "from df_engine.core import Context, Actor\n",
    "import df_engine.conditions as cnd\n",
    "import df_engine.responses\n",
    "import df_engine.labels as lbl\n",
    "from examples import example_1_basics\n",
    "from df_engine.core.types import NodeLabel3Type\n",
    "from typing import Union, Optional, Any\n",
    "from numpy import random\n",
    "import logging\n",
    "import re\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, here is the example of a chatbot in DialogFlow Framework. We will explain every function and give references to the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='complex'></a>\n",
    "\n",
    "This is the [condition](#dfe_condition) function, that checks if user text is castable to string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def complex_user_answer_condition(ctx: Context, actor: Actor, *args, **kwargs) -> bool:\n",
    "    request = ctx.last_request\n",
    "    request_is_castable = False\n",
    "    try:  # check if request is castable from str\n",
    "        request = eval(request)\n",
    "        request_is_castable = True\n",
    "    except:\n",
    "        pass\n",
    "    return request_is_castable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the example of  [transition](#transition) function, that returns tuple (name of flow, name of node,  [priority](#selecting) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_node_ok_transition(ctx: Context, actor: Actor, *args, **kwargs) -> NodeLabel3Type:\n",
    "    return (\"flow\", \"node_ok\", 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the example of [PRE_TRANSITION_PROCESSING](#transition)  .\n",
    "It saves the response  to the `previous_node_response` field of `MISC`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_previous_node_response_to_ctx_processing(ctx: Context, actor: Actor, prefix=None, *args, **kwargs) -> Context:\n",
    "    processed_node = ctx.current_node\n",
    "    ctx.misc[\"previous_node_response\"] = processed_node.response\n",
    "    return ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the example of [PRE_RESPONSE_PROCESSING](#response) .\n",
    "    \n",
    "It returns function that adds to the response prefix, and calls the response function if the response is callable.\n",
    "    \n",
    "Note that we need to overwrite the current node with the modified node, \n",
    "calling `ctx.overwrite_current_node_in_processing(processed_node)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prefix(prefix):\n",
    "    def add_prefix_processing(ctx: Context, actor: Actor, *args, **kwargs) -> Context:\n",
    "        processed_node = ctx.current_node\n",
    "        if not callable(processed_node.response):\n",
    "            processed_node.response = f\"{prefix}: {processed_node.response}\"\n",
    "        elif callable(processed_node.response):\n",
    "            processed_node.response = f\"{prefix}: {processed_node.response(ctx, actor, *args, **kwargs)}\"\n",
    "        # overwriting the node for context \n",
    "        ctx.overwrite_current_node_in_processing(processed_node)\n",
    "        return ctx\n",
    "\n",
    "    return add_prefix_processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is another example of [PRE_RESPONSE_PROCESSING](#response) . \n",
    "\n",
    "It returns function that adds to the response content of MISC dictionary as prefix,\n",
    "and calls the response function if the response is callable.\n",
    "\n",
    "Note that we need to overwrite the current node with the modified node, \n",
    "calling `ctx.overwrite_current_node_in_processing(processed_node)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_misc():\n",
    "    def add_misc_processing(ctx: Context, actor: Actor, *args, **kwargs) -> Context:\n",
    "        processed_node = ctx.current_node\n",
    "        if not callable(processed_node.response):\n",
    "            processed_node.response = f\"misc: {processed_node.misc} {processed_node.response}\"\n",
    "        elif callable(processed_node.response):\n",
    "            processed_node.response = (\n",
    "                f\"misc: {processed_node.misc} \" f\"{processed_node.response(ctx, actor, *args, **kwargs)}\"\n",
    "            )\n",
    "        ctx.overwrite_current_node_in_processing(processed_node)\n",
    "        return ctx\n",
    "\n",
    "    return add_misc_processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='talk_about_response'></a>\n",
    "\n",
    "This is the example of [PRE_RESPONSE_PROCESSING](#response) \n",
    "\n",
    "It returns function that adds to the response prefix, and calls the response function if it is callable.\n",
    "    \n",
    "Note that we need to overwrite the current node with the modified node, \n",
    "calling `ctx.overwrite_current_node_in_processing(processed_node)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_priority_node_transition(flow_label, label):\n",
    "    def transition(ctx: Context, actor: Actor, *args, **kwargs) -> NodeLabel3Type:\n",
    "        return (flow_label, label, 2.0)\n",
    "\n",
    "    return transition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the simple [response](#response) function. Later, it will be called just in script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_case_response(response: str):\n",
    "    return response.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is another example of the [response](#response) function. It does not take any argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def okay_response():\n",
    "    return random.choice(['OKAY', 'OK'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the [response](#response) function, that logs the context and returns the dictionary with previous node and last request.\n",
    "Unlike previous 2 functions it does not need to be called. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fallback_trace_response(ctx: Context, actor: Actor, *args, **kwargs) -> Any:\n",
    "    logger.warning(f\"ctx={ctx}\")\n",
    "    return str(\n",
    "        {\n",
    "            \"previous_node\": list(ctx.labels.values())[-2],\n",
    "            \"last_request\": ctx.last_request,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='talk_about_response'></a>\n",
    "\n",
    "This is also a [response](#response) function. \n",
    "    \n",
    "It finds whether user said \"Talk about ANY_WORD\" , where ANY_WORD is literally any word.\n",
    "\n",
    "If the WORD is found, the response is \"Sorry, I can not talk about WORD now. \" \n",
    "\n",
    "Otherwise it says \"Sorry, I can not talk about that now. \"\n",
    "\n",
    "In any case, it prepends length of the dialog (in number of bot utterances) to the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Context' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-fe939053d67f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mtalk_about_topic_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mActor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtopic_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"(.*talk about )(.*)\\.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtopic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic_pattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtopic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Context' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def talk_about_topic_response(ctx: Context, actor: Actor, *args, **kwargs) -> Any:\n",
    "    request = ctx.last_request\n",
    "    topic_pattern = re.compile(r\"(.*talk about )(.*)\\.\")\n",
    "    topic = topic_pattern.findall(request)\n",
    "    topic = topic and topic[0] and topic[0][-1]\n",
    "    if topic:\n",
    "        return f\"Sorry, I can not talk about {topic} now. {len(ctx.requests)}\"\n",
    "    else:\n",
    "        return f\"Sorry, I can not talk about that now. {len(ctx.requests)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of [condition](#dfe_condition) function. It returns `True` only if the last user utterance contains \"talk about. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id='talk about'></a>\n",
    "\n",
    "def talk_about_topic_condition(ctx: Context, actor: Actor, *args, **kwargs) -> bool:\n",
    "    request = ctx.last_request\n",
    "    return \"talk about\" in request.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of [condition](#dfe_condition) function. It returns `True` only if the last user utterance contains \"no \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_lower_case_condition(ctx: Context, actor: Actor, *args, **kwargs) -> bool:\n",
    "    request = ctx.last_request\n",
    "    return \"no\" in request.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create script of dialog\n",
    "\n",
    "script = {\n",
    "    GLOBAL: {\n",
    "        TRANSITIONS: {\n",
    "            (\"global_flow\", \"start_node\", 1.5): cnd.exact_match(\"global start\"),\n",
    "            (\"flow\", \"node_hi\", 1.5): cnd.exact_match(\"global hi\"),\n",
    "        },\n",
    "        MISC: {\"var1\": \"global_data\", \"var2\": \"global_data\", \"var3\": \"global_data\"},\n",
    "        PRE_RESPONSE_PROCESSING: {\n",
    "            \"proc_name_1\": add_prefix(\"l1_global\"),\n",
    "        },\n",
    "        PRE_TRANSITIONS_PROCESSING: {\"proc_tr__name_1\": save_previous_node_response_to_ctx_processing},\n",
    "    },\n",
    "    \"global_flow\": {\n",
    "        \"start_node\": {\n",
    "            RESPONSE: \"INITIAL NODE\",\n",
    "            TRANSITIONS: {\n",
    "                (\"flow\", \"node_hi\"): cnd.regexp(r\"base\"),\n",
    "                \"fallback_node\": cnd.true(),\n",
    "            },\n",
    "        },\n",
    "        \"fallback_node\": {\n",
    "            RESPONSE: \"oops\",\n",
    "            TRANSITIONS: {\n",
    "                lbl.previous(): cnd.exact_match(\"initial\"),\n",
    "                # to global flow start node\n",
    "                lbl.repeat(): cnd.true()\n",
    "                # global flow, fallback node\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"flow\": {\n",
    "        LOCAL: {\n",
    "            MISC: {\n",
    "                \"var2\": \"rewrite_by_flow\",\n",
    "                \"var3\": \"rewrite_by_flow\",\n",
    "            },\n",
    "            PRE_RESPONSE_PROCESSING: {\n",
    "                \"proc_name_1\": add_prefix(\"l1_flow\"),\n",
    "            },\n",
    "            PRE_TRANSITIONS_PROCESSING: {\"proc_tr__name_2\": save_previous_node_response_to_ctx_processing},\n",
    "        },\n",
    "        \"node_hi\": {\n",
    "            MISC: {\"var3\": \"rewrite_by_hi\"},\n",
    "            PRE_RESPONSE_PROCESSING: {\n",
    "                \"proc_name_1\": add_prefix(\"l1_flow_hi\"),\n",
    "                \"proc_name_2\": add_misc(),\n",
    "            },\n",
    "            RESPONSE: \"Hi!!!\",\n",
    "            TRANSITIONS: {\n",
    "                (\"flow\", \"node_complex\"): complex_user_answer_condition,\n",
    "                (\"flow\", \"node_hi\"): cnd.exact_match(\"Hi\"),\n",
    "                high_priority_node_transition(\"flow\", \"node_no\"): no_lower_case_condition,\n",
    "                (\"flow\", \"node_topic\"): talk_about_topic_condition,\n",
    "                flow_node_ok_transition: cnd.all([cnd.true(), cnd.has_last_labels(flow_labels=[\"global_flow\"])]),\n",
    "            },\n",
    "        },\n",
    "        \"node_no\": {\n",
    "            MISC: {\"var3\": \"rewrite_by_NO\"},\n",
    "            PRE_RESPONSE_PROCESSING: {\n",
    "                \"proc_name_1\": add_prefix(\"l1_flow_no\"),\n",
    "                \"proc_name_2\": add_misc(),\n",
    "            },\n",
    "            RESPONSE: upper_case_response(\"NO\"),\n",
    "            TRANSITIONS: {\n",
    "                (\"flow\", \"node_complex\"): complex_user_answer_condition,\n",
    "                (\"flow\", \"node_hi\"): cnd.regexp(r\"hi\"),\n",
    "                (\"flow\", \"node_topic\"): talk_about_topic_condition,\n",
    "            },\n",
    "        },\n",
    "        \"node_complex\": {\n",
    "            MISC: {\"var3\": \"rewrite_by_COMPLEX\"},\n",
    "            PRE_RESPONSE_PROCESSING: {\n",
    "                \"proc_name_1\": add_prefix(\"l1_flow_complex\"),\n",
    "                \"proc_name_2\": add_misc(),\n",
    "            },\n",
    "            RESPONSE: \"Not string detected\",\n",
    "            TRANSITIONS: {\n",
    "                (\"flow\", \"node_complex\"): complex_user_answer_condition,\n",
    "                (\"flow\", \"node_hi\"): cnd.regexp(r\"hi\"),\n",
    "                lbl.to_fallback(0.1): cnd.true(),\n",
    "            },\n",
    "        },\n",
    "        \"node_topic\": {\n",
    "            MISC: {\"var3\": \"rewrite_by_TOPIC\"},\n",
    "            PRE_RESPONSE_PROCESSING: {\n",
    "                \"proc_name_1\": add_prefix(\"l1_flow_topic\"),\n",
    "                \"proc_name_2\": add_misc(),\n",
    "            },\n",
    "            RESPONSE: talk_about_topic_response,\n",
    "            TRANSITIONS: {\n",
    "                lbl.forward(0.5): cnd.any([cnd.regexp(r\"ok\"), cnd.regexp(r\"o k\")]),\n",
    "                lbl.backward(0.5): cnd.any([cnd.regexp(r\"node complex\"), complex_user_answer_condition]),\n",
    "            },\n",
    "        },\n",
    "        \"node_ok\": {\n",
    "            MISC: {\"var3\": \"rewrite_by_OK\"},\n",
    "            PRE_RESPONSE_PROCESSING: {\n",
    "                \"proc_name_1\": add_prefix(\"l1_flow_ok\"),\n",
    "                \"proc_name_2\": add_misc(),\n",
    "            },\n",
    "            RESPONSE: okay_response(),\n",
    "            TRANSITIONS: {\n",
    "                (\"flow\", \"node_complex\"): complex_user_answer_condition,\n",
    "                lbl.previous(): cnd.regexp(r\"previous\"),\n",
    "            },\n",
    "        },\n",
    "        \"fallback_node\": {  # We get to this node if an error occurred while the agent was running\n",
    "            RESPONSE: fallback_trace_response,\n",
    "            TRANSITIONS: {\n",
    "                (\"flow\", \"node_complex\"): complex_user_answer_condition,\n",
    "                \"node_hi\": cnd.all([cnd.exact_match(\"Hi\"), cnd.exact_match(\"Hello\")]),\n",
    "                \"node_ok\": cnd.exact_match(\"Okey\"),\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we initialize `actor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init actor\n",
    "actor = Actor(\n",
    "    script,\n",
    "    start_label=(\"global_flow\", \"start_node\"),\n",
    "    fallback_label=(\"global_flow\", \"fallback_node\"),\n",
    "    label_priority=1.0,\n",
    ")\n",
    "\n",
    "\n",
    "# handler requests\n",
    "\n",
    "# turn_handler - a function is made for the convenience of working with an actor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we initialize `turn_handler`.\n",
    "\n",
    "Note that if the argument `true_out_response` is given, it is nust be the same as outputted response.\n",
    "Otherwise we get an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_handler(\n",
    "    in_request: str,\n",
    "    ctx: Union[Context, str, dict],\n",
    "    actor: Actor,\n",
    "    true_out_response: Optional[str] = None,\n",
    "):\n",
    "    # Context.cast - gets an object type of [Context, str, dict] returns an object type of Context\n",
    "    ctx = Context.cast(ctx)\n",
    "    # Add in current context a next request of user\n",
    "    ctx.add_request(in_request)\n",
    "    # pass the context into actor and it returns updated context with actor response\n",
    "    ctx = actor(ctx)\n",
    "    #  breakpoint()\n",
    "    # get last actor response from the context\n",
    "    out_response = ctx.last_response\n",
    "    # the next condition branching needs for testing\n",
    "    if true_out_response is not None and true_out_response != out_response:\n",
    "        print(\"request\")\n",
    "        print(in_request)\n",
    "        print(\"response was\")\n",
    "        print(out_response)\n",
    "        print(\"response must be\")\n",
    "        print(true_out_response)\n",
    "        msg = f\"in_request={in_request} -> true_out_response != out_response: {true_out_response} != {out_response}\"\n",
    "        raise Exception(msg)\n",
    "    else:\n",
    "        print(f\"in_request={in_request} -> NODE {list(ctx.labels.values())[-1]} RESPONSE {out_response}\")\n",
    "    return out_response, ctx\n",
    "\n",
    "\n",
    "# edit this dialog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will make an example of testing dialog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTING_DIALOG = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the <b>start_node</b> from `global_flow` . \n",
    "\n",
    "Initially, values of `MISC` variables `var1`, `var2` and `var3` were equal to `global_data` as set in `GLOBAL`.\n",
    "\n",
    "With the user request \"base\", condition for transition to <b>node_hi</b> from `flow` triggered.\n",
    "\n",
    "and the condition for transition to the fallback_node from global_flow triggered.\n",
    "\n",
    "Using [these](#transition) rules, bot made a transition to node hi from flow.\n",
    "\n",
    "In this new flow, variables `var2` and `var3` were rewritten to rewrite_by_flow as described [here](#overwrite)\n",
    "\n",
    "Just after that, variable `var3` was again rewritten to rewrite_by_hi on the level of <b>node_hi</b>.\n",
    "\n",
    "In this node,  `PRE_RESPONSE_PROCESSING` from proc_name_1 was used.\n",
    "\n",
    "By executing function add_prefix with \"l1_flow_hi\", \"l1_flow_hi\" was prepended to the `RESPONSE` from the left.\n",
    "\n",
    "Then, `PRE_RESPONSE_PROCESSING` from proc_name_2 was used.\n",
    "\n",
    "It executed function `add_misc()`, \n",
    "prepending to the response string \"misc: {'var1': 'global_data', 'var2': 'rewrite_by_flow', 'var3': 'rewrite_by_hi'}\"\" \n",
    "\n",
    "This string contains string of all MISC values after the string \"misc:\"\n",
    "\n",
    "So the final answer on base is the same as on ANSWER_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UTTERANCE_1 = \"base\"\n",
    "ANSWER_1 =  \"misc: {'var1': 'global_data', 'var2': 'rewrite_by_flow', 'var3': 'rewrite_by_hi'} \" \\\n",
    "                \"l1_flow_hi: Hi!!!\"\n",
    "TESTING_DIALOG.append((UTTERANCE_1, ANSWER_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the transitions in <b>node_hi</b>, only transition to <b>node_no</b> was fulfilled.\n",
    "\n",
    "In this node, variable `var3` was rewritten and first `PRE_RESPONSE_PROCESSING` ( name `proc_name_1` ) also was rewritten. \n",
    "\n",
    "Then, rewritten `PRE_RESPONSE_PROCESSING` functions were executed for response just like in the previous turn.\n",
    "Note that the response by itself was the result of function ```upper_case_response(\"NO\")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UTTERANCE_2 = \"no\"\n",
    "ANSWER_2 =\"misc: {'var1': 'global_data', 'var2': 'rewrite_by_flow', 'var3': 'rewrite_by_NO'} \" \\\n",
    "               \"l1_flow_no: NO\"\n",
    "TESTING_DIALOG.append((UTTERANCE_2, ANSWER_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the transitions in <b>node_no</b>, conditions for transitions to <b>node_complex</b> and <b>node_hi</b> were not fulfilled.\n",
    "\n",
    "However, condition for transition to <b>node_topic</b> was fulfilled (as utterance triggered the [function](#talk_about) )\n",
    "\n",
    "So the response was obtained using this [function](#talk_about_response) , with a preprocessing as on the previous stages:\n",
    "    `var3` variable rewritten, `misc` value and node_specific prefix prepended.\n",
    "\n",
    "This function was given as an argument without execution ( unlike previous function) , as it takes `context` and `actor` as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UTTERANCE_3 = \"talk about books\"\n",
    "ANSWER_3 = \"misc: {'var1': 'global_data', 'var2': 'rewrite_by_flow', 'var3': 'rewrite_by_TOPIC'} \" \\\n",
    "            \"l1_flow_topic: Sorry, I can not talk about that now. 3\"\n",
    "TESTING_DIALOG.append((UTTERANCE_3, ANSWER_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the possible transitions in <b>node_topic</b>, only transition to <b>node_ok</b> was satisfied.\n",
    "\n",
    "This is because condition `cnd.regexp(r\"ok\")` was satisfied. So, transition with condition `cnd.any([cnd.regexp(r\"ok\"), cnd.regexp(r\"o k\")])` was executed.\n",
    "\n",
    "So we went to the <b>node_ok</b> where `add_prefix` function switched to <i>l1_flow_ok</i> and variable name of `var3` changed to <i>rewrite_by_ok</i>\n",
    "\n",
    "Then, with prepending 2 pre_response_processings, response function was executed.It randomly chooses between OK and OKAY.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UTTERANCE_4 = \"ok\"\n",
    "ANSWER_4 = \"misc: {'var1': 'global_data', 'var2': 'rewrite_by_flow', 'var3': 'rewrite_by_OK'} \" \\\n",
    "           \"l1_flow_ok: OK\"\n",
    "TESTING_DIALOG.append((UTTERANCE_4, ANSWER_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the transitions in <b>node_ok</b>, transition with `complex_user_answer_condition` was not satisfied\n",
    "as the word previous is not castable to anything other than string.\n",
    "\n",
    "However, transition to [`lbl.previous()`](#dfe_labels) was satisfied, as the `cnd.regexp(r\"previous\")` was satisfied.\n",
    "\n",
    "`lbl.previous()` redirected the user to the node which was visited by user before the <b>node_ok</b>. This is <b>node_topic</b>.\n",
    "\n",
    "On this node, the response was processed in the same way as it was the last time we were in this node, with the exception that the dialog length is higher by 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UTTERANCE_5 = \"previous\"\n",
    "ANSWER_5 =  \"misc: {'var1': 'global_data', 'var2': 'rewrite_by_flow', 'var3': 'rewrite_by_TOPIC'} \" \\\n",
    "            \"l1_flow_topic: Sorry, I can not talk about that now. 5\",\n",
    "TESTING_DIALOG.append((UTTERANCE_5, ANSWER_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the transitions in <b>node_topic</b>,\n",
    "transition with condition  ```cnd.any([cnd.regexp(r\"ok\"), cnd.regexp(r\"o k\")])``` was not satisfied \n",
    "as there were no 'ok' and 'o k' in the string.\n",
    "\n",
    "However, condition ```cnd.any([cnd.regexp(r\"node complex\"), complex_user_answer_condition])``` was satisfied, \n",
    "as [complex](#complex_answer_condition) was executed to '{1:2}' and outputted True, \n",
    "just because ```'{1:2}'``` is castable to anything other than string.\n",
    "    \n",
    "So, despite ```cnd.regexp(r\"node complex\")``` was not fulffilled, condition `cnd.any` was fulfilled and we went to the <b>node_complex</b>.\n",
    "    In this node, `var3` from `MICS` was rewritten, and output with two `PRE_RESPONSE_PROCESSING`s, in the same way as in previous nodes, was executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UTTERANCE_6 = \"{1:2}\"\n",
    "ANSWER_6 = \"misc: {'var1': 'global_data', 'var2': 'rewrite_by_flow', 'var3': 'rewrite_by_COMPLEX'} \" \\\n",
    "           \"l1_flow_complex: Not string detected\",\n",
    "TESTING_DIALOG.append((UTTERANCE_6, ANSWER_6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the transitions in <b>node_complex</b>,\n",
    "only one condition was fulfilled: condition `lbl.to_fallback(0.1)`, as it is always True\n",
    "    \n",
    "Hence, the next node was <b>fallback_node</b> from the global flow. The only `PRE_RESPONSE_PROCESSING` that works there is `PRE_RESPONSE_PROCESSING` on the `GLOBAL` level(as it is not [overwritten](#overwrite) by other nodes)\n",
    "It added prefix `l1_global` to the `RESPONSE` \"oops\". So the answer is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UTTERANCE_7 = \"f\"\n",
    "ANSWER_7 = \"l1_global: oops\"\n",
    "TESTING_DIALOG.append((UTTERANCE_7, ANSWER_7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the function for testing the dialog by executing `turn_handler`.\n",
    "In `turn_handler`, this function checks whether the bot outputs the same responses as we want.\n",
    "\n",
    "The function has the functionality to cast context to string or json, as in [Example 6](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_6_context_serialization.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(mode=None):\n",
    "    ctx = {}\n",
    "    for in_request, true_out_response in TESTING_DIALOG:\n",
    "        _, ctx = turn_handler(in_request, ctx, actor, true_out_response=true_out_response)\n",
    "        if mode == \"json\":\n",
    "            ctx = ctx.json()\n",
    "            if isinstance(ctx, str):\n",
    "                logging.info(\"context serialized to json str\")\n",
    "            else:\n",
    "                raise Exception(f\"ctx={ctx} has to be serialized to json string\")\n",
    "        elif mode == \"dict\":\n",
    "            ctx = ctx.dict()\n",
    "            if isinstance(ctx, dict):\n",
    "                logging.info(\"context serialized to dict\")\n",
    "            else:\n",
    "                raise Exception(f\"ctx={ctx} has to be serialized to dict\")\n",
    "run_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the function for interacting with chatbot. This function repeatedly asks user for an input and gives this input to the `turn_handler`, which logs an output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive mode\n",
    "def run_interactive_mode(actor):\n",
    "    ctx = {}\n",
    "    while True:\n",
    "        in_request = input(\"type your answer: \")\n",
    "        _, ctx = turn_handler(in_request, ctx, actor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can chat with your chatbot. Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                          \n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s-%(name)15s:%(lineno)3s:%(funcName)20s():%(levelname)s - %(message)s\",\n",
    "        level=logging.INFO,\n",
    "    )\n",
    "    # run_test()\n",
    "    run_interactive_mode(actor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
